# Great Video Understanding
## [In the process of updating]

### Papers
##### 1. Context R-CNN: Long Term Temporal Context for Per-Camera Object Detection Sara [CVPR 2020] [paper link](https://arxiv.org/abs/1912.03538)
##### 2. NeRV: Neural Representations for Videos [NeurIPS 2021] [paper link](https://arxiv.org/abs/2110.13903)

=====================================================================================
### Datasets
#### 1.[Snapshot Serengeti](https://lila.science/datasets/snapshot-serengeti/): This data set contains approximately 2.65M sequences of camera trap images, totaling 7.1M images
#### 2.[Caltech Cam- era Traps (CCT)](https://beerys.github.io/CaltechCameraTraps/): The dataset contains 243,187 images from 140 camera locations.
#### 3.[CityCam](https://www.citycam-cmu.com/dataset): The dataset contains 60,000 frames with rich information, leading to about 900,000 annotated objects.
#### 4.[UVG](http://ultravideo.fi/#testsequences):  This dataset is composed of 16 versatile 4K (3840Ã—2160) test video sequences captured at 50/120 fps.
