# Great Video Understanding
## [In the process of updating]

### Papers
##### 1. Context R-CNN: Long Term Temporal Context for Per-Camera Object Detection Sara [CVPR 2020] [paper link](https://arxiv.org/abs/1912.03538)
##### 2. NeRV: Neural Representations for Videos [NeurIPS 2021] [paper link](https://arxiv.org/abs/2110.13903)

=====================================================================================
### Datasets
##### 1.[Snapshot Serengeti](https://lila.science/datasets/snapshot-serengeti/): Approximately 2.65M sequences of camera trap images, totaling 7.1M images
##### 2.[Caltech Camera Traps (CCT)](https://beerys.github.io/CaltechCameraTraps/): 243,187 images from 140 camera locations.
##### 3.[CityCam](https://www.citycam-cmu.com/dataset): 60,000 frames with rich information, leading to about 900,000 annotated objects.
##### 4.[UVG](http://ultravideo.fi/#testsequences):  16 versatile 4K (3840Ã—2160) test video sequences captured at 50/120 fps.
